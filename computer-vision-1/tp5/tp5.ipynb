{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP5\n",
    "\n",
    "Elaborado por: Alan Churichi\n",
    "\n",
    "## Objetivo: \n",
    "\n",
    "- Implementar el detector de fondo naive usando la mediana como estimador. El algoritmo debe recibir el parámetro N (cantidad de frames utilizados para la estimación) y el intervalo de tiempo para recalcular el fondo.\n",
    "- Se deben generar las mascaras de foreground y aplicarlas a los frames para segmentar los objetos en movimiento.\n",
    "- Comparar con alguno de los métodos vistos en la practica basados en mezcla de gaussianas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/tf/notebooks/CEIA/computer-vision-1/tp5/assets\"\n",
    "video_path = os.path.join(base_path, \"vtest.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que se hace es generar un conjunto de funciones que nos serán de utilidad en nuestra función para remover el fondo.\n",
    "\n",
    "- `get_random_frames`: toma una muestra aleatoria de n frames en el rango especificado.\n",
    "- `get_n_frames`: toma una muestra de n frames consecutivos.\n",
    "- `write_filename`: toma una frame y le aplica un recuadro con el texto especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_frames(cap, n_samples, start, end):\n",
    "    start_frame = cap.get(cv.CAP_PROP_POS_FRAMES)\n",
    "    random_indices = [random.randint(start, end) for _ in range(n_samples)]\n",
    "    frames = []\n",
    "\n",
    "    for index in random_indices:\n",
    "        cap.set(cv.CAP_PROP_POS_FRAMES, index)\n",
    "        frames.append(cap.read()[1])\n",
    "\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "def get_n_frames(cap, n_samples):\n",
    "    start_frame = cap.get(cv.CAP_PROP_POS_FRAMES)\n",
    "    frames = []\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        cap.set(cv.CAP_PROP_POS_FRAMES, start_frame + i)\n",
    "        frames.append(cap.read()[1])\n",
    "\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "def write_filename(frame, filename):\n",
    "    cv.rectangle(frame, (10, 2), (300, 20), (255, 255, 255), -1)\n",
    "    cv.putText(\n",
    "        frame,\n",
    "        filename,\n",
    "        (15, 15),\n",
    "        cv.FONT_HERSHEY_SIMPLEX,\n",
    "        0.5,\n",
    "        (0, 0, 0),\n",
    "    )\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función principar `remove_bg`, el funcionamiento es el siguiente:\n",
    "\n",
    "- Se carga el video desde el path especifcado.\n",
    "- Se calculan características del video como el numero total de frames, los fps y la cantidad de frames para actualizar la mediana de comparación.\n",
    "- Se itera por steps, que son los intervalos en los que se debe calcular la mediana. En cada step se calcula la mediana, si es la primera iteración se toman los n primeros frames, sino se toman n frames aleatorios en el rango del step anterior.\n",
    "- En cada step se itera sobre todos los frames dentro de ese step y se calcula el fondo haciendo la resta del `frame` - `mediana` en escala de grises.\n",
    "- Se binariza el resultado y, de manera opcional, se hace una operación morfológica de apertura.\n",
    "- Se utiliza `VideoWriter` para guardar el stream frame a frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bg(video_path, dst_path, bg_samples, recalculation, apply_morph=True):\n",
    "    \"\"\"\n",
    "    Remueve el backgound de un video\n",
    "    Argumentos:\n",
    "        video_path: Path del video a procesar\n",
    "        dst_path: Path donde guardar la mascara\n",
    "        bg_samples: El numero de muestras a tomar para calcular el background\n",
    "        recalculation: Intervalo en segundos para recalcular la mediana\n",
    "        apply_morph: Si se desea o no aplicar apertura al resultado\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    video_writer = cv.VideoWriter(dst_path, 0, fps, (width, height))\n",
    "\n",
    "    step = recalculation * fps\n",
    "\n",
    "    for lower_limit in range(0, total_frames, step):\n",
    "        upper_limit = min(lower_limit + step, total_frames)\n",
    "        progress = int(lower_limit / total_frames * 100)\n",
    "        print(f\"Generando video {progress}%\")\n",
    "\n",
    "        if lower_limit < step:\n",
    "            random_frames = get_n_frames(cap, bg_samples)\n",
    "        else:\n",
    "            random_frames = get_random_frames(\n",
    "                cap, bg_samples, lower_limit - step, lower_limit\n",
    "            )\n",
    "\n",
    "        median = np.median(random_frames, axis=0)\n",
    "        median_gray = cv.cvtColor(median.astype(np.uint8), cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        for i in range(lower_limit, upper_limit):\n",
    "            frame = cap.read()[1]\n",
    "            frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "            diff = cv.absdiff(frame_gray, median_gray)\n",
    "            _, result = cv.threshold(diff, 30, 255, cv.THRESH_BINARY)\n",
    "            if apply_morph:\n",
    "                result = cv.morphologyEx(\n",
    "                    result, cv.MORPH_OPEN, np.ones((3, 3), np.uint8)\n",
    "                )\n",
    "            result = write_filename(result, os.path.basename(dst_path))\n",
    "\n",
    "            video_writer.write(cv.cvtColor(result, cv.COLOR_GRAY2BGR))\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Generando video 100%\")\n",
    "    print(f\"Tiempo empleado: {elapsed_time:.3f} segundos\")\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "    cap.release()\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando video 0%\n",
      "Generando video 12%\n",
      "Generando video 25%\n",
      "Generando video 37%\n",
      "Generando video 50%\n",
      "Generando video 62%\n",
      "Generando video 75%\n",
      "Generando video 88%\n",
      "Generando video 100%\n",
      "Tiempo empleado: 35.352 segundos\n"
     ]
    }
   ],
   "source": [
    "dst_path = os.path.join(base_path, \"output-median.avi\")\n",
    "remove_bg(video_path, dst_path, 60, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvo el siguente resultado:\n",
    "\n",
    "<img src=\"assets/example-output-median.png\" width=\"800\" align=\"center\">\n",
    "\n",
    "Probamos el mismo algorimto pero esta vez sin aplicar apertura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando video 0%\n",
      "Generando video 12%\n",
      "Generando video 25%\n",
      "Generando video 37%\n",
      "Generando video 50%\n",
      "Generando video 62%\n",
      "Generando video 75%\n",
      "Generando video 88%\n",
      "Generando video 100%\n",
      "Tiempo empleado: 35.095 segundos\n"
     ]
    }
   ],
   "source": [
    "dst_path = os.path.join(base_path, \"output-median-no-morph.avi\")\n",
    "remove_bg(video_path, dst_path, 60, 10, apply_morph=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvo el siguente resultado:\n",
    "\n",
    "<img src=\"assets/example-output-median-no-morph.png\" width=\"800\" align=\"center\">\n",
    "\n",
    "Definimos una nueva función que utiliza los algoritmos de eliminación de background provistos por OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_cv_remove_bg(video_path, dst_path, method=\"MOG2\"):\n",
    "    \"\"\"\n",
    "    Remueve el backgound de un video utilizando algoritmos de OpenCV\n",
    "    Argumentos:\n",
    "        video_path: Path del video a procesar\n",
    "        dst_path: Path donde guardar la mascara\n",
    "        method: Algoritmo de OpenCV a utilizar\n",
    "    \"\"\"\n",
    "\n",
    "    if method == \"MOG2\":\n",
    "        bg_sub = cv.createBackgroundSubtractorMOG2()\n",
    "    elif method == \"KNN\":\n",
    "        bg_sub = cv.createBackgroundSubtractorKNN()\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv.CAP_PROP_FPS))\n",
    "    video_writer = cv.VideoWriter(dst_path, 0, fps, (width, height))\n",
    "\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        mask = bg_sub.apply(frame)\n",
    "        result = write_filename(mask, os.path.basename(dst_path))\n",
    "\n",
    "        video_writer.write(cv.cvtColor(result, cv.COLOR_GRAY2BGR))\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Tiempo empleado: {elapsed_time:.3f} segundos\")\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "    cap.release()\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo empleado: 5.723 segundos\n"
     ]
    }
   ],
   "source": [
    "dst_path = os.path.join(base_path, \"opencv-MOG2.avi\")\n",
    "open_cv_remove_bg(video_path, dst_path, method=\"MOG2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvo el siguente resultado:\n",
    "\n",
    "<img src=\"assets/example-opencv-MOG2.png\" width=\"800\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo empleado: 5.170 segundos\n"
     ]
    }
   ],
   "source": [
    "dst_path = os.path.join(base_path, \"opencv-KNN.avi\")\n",
    "open_cv_remove_bg(video_path, dst_path, method=\"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvo el siguente resultado:\n",
    "\n",
    "<img src=\"assets/example-opencv-KNN.png\" width=\"800\" align=\"center\">\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "En base a las pruebas realizadas se obtuvieron la siguentes conclusiones:\n",
    "\n",
    "- Todos los algoritmos dan resutlados bastante buenos a la hora de separar el fondo de los objetos en movimiento.\n",
    "- Los métodos de OpenCV son aproximadamente 7 veces más rápido que el que algoritmo de mediana que se implementó.\n",
    "- El algoritmo implementado tiene menos ruido que los métodos de OpenCV.\n",
    "- Utilizar apertura no hace el algoritmo mucho más lento. Aproximadamente 200ms más.\n",
    "- Utilizar apertura elimina en cierta medida el ruido pero también deforma la máscara.\n",
    "- En los videos del algoritmo implementado se puede apreciar cierto ruido, de imagénes estáticas, producto de los tiempos de actualización del filtro de mediana.\n",
    "- La forma en la que se codifica el video no es la más óptima, ya que los archivos de salida tienen un peso de 527Mb. Siendo que el archivo de lectura pesa solamente 8Mb.\n",
    "\n",
    "Se puede ver el video con la comparativa de las 4 pruebas realizadas en el siguiente [link](https://youtu.be/eNfNtkFaRwY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
