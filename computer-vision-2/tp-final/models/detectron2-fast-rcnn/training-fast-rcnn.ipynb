{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install torch==1.10.2+cu113 torchvision==0.11.3+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# !pip install detectron2==0.6 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html\n",
        "# !pip install setuptools==59.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import detectron2\n",
        "import detectron2.data.transforms as T\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import DatasetMapper, MetadataCatalog, build_detection_train_loader, build_detection_test_loader\n",
        "from detectron2.data.catalog import DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.utils.logger import setup_logger\n",
        "\n",
        "setup_logger()\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch, torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "DETECTRON_2_BASE_PATH = \"/tf/datasets/final-dataset/detectron2-dataset\"\n",
        "\n",
        "DETECTRON_2_DATASET_PATHS = {\n",
        "    \"train\": os.path.join(DETECTRON_2_BASE_PATH, \"train\"),\n",
        "    \"val\": os.path.join(DETECTRON_2_BASE_PATH, \"val\"),\n",
        "    \"test\": os.path.join(DETECTRON_2_BASE_PATH, \"test\"),\n",
        "}\n",
        "\n",
        "for subset in DETECTRON_2_DATASET_PATHS.keys():\n",
        "    register_coco_instances(\n",
        "        name=f\"custom_dataset_{subset}\",\n",
        "        metadata={},\n",
        "        json_file=os.path.join(\n",
        "            DETECTRON_2_DATASET_PATHS[subset], \"_annotations.coco.json\"\n",
        "        ),\n",
        "        image_root=DETECTRON_2_DATASET_PATHS[subset],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CocoTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        mapper = DatasetMapper(\n",
        "            cfg,\n",
        "            is_train=True,\n",
        "            augmentations=[\n",
        "                T.Resize((400, 400)),\n",
        "                T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
        "                T.RandomSaturation(intensity_min=0.8, intensity_max=1.2),\n",
        "                T.RandomBrightness(intensity_min=0.8, intensity_max=1.2),\n",
        "                T.RandomContrast(intensity_min=0.8, intensity_max=1.2),\n",
        "            ],\n",
        "        )\n",
        "        return build_detection_train_loader(cfg, mapper=mapper)\n",
        "\n",
        "    @classmethod\n",
        "    def build_test_loader(cls, cfg, name=\"test\"):\n",
        "        mapper = DatasetMapper(\n",
        "            cfg,\n",
        "            is_train=False,\n",
        "            augmentations=[T.Resize((400, 400))],\n",
        "        )\n",
        "        return build_detection_test_loader(cfg, name, mapper=mapper)\n",
        "\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "\n",
        "        if output_folder is None:\n",
        "            os.makedirs(\"coco_eval\", exist_ok=True) # arreglar esto\n",
        "            output_folder = \"coco_eval\"\n",
        "\n",
        "        return COCOEvaluator(dataset_name, (\"bbox\",), False, output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUNS_PATH = \"/tf/notebooks/CEIA/computer-vision-2/tp-final/runs\"\n",
        "TRAIN_PROJECT_PATH = os.path.join(RUNS_PATH, \"train\")\n",
        "\n",
        "experiment = 'detectron2-rcnn-2000-epochs'\n",
        "experimentPath =  os.path.join(TRAIN_PROJECT_PATH, experiment)\n",
        "\n",
        "\n",
        "CONFIG_FILE = \"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE))\n",
        "cfg.DATASETS.TRAIN = (\"custom_dataset_train\",)\n",
        "cfg.DATASETS.TEST = (\"custom_dataset_val\",)\n",
        "cfg.OUTPUT_DIR = experimentPath\n",
        "\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE)\n",
        "cfg.SOLVER.IMS_PER_BATCH = 16\n",
        "cfg.SOLVER.BASE_LR = 0.001\n",
        "\n",
        "# cfg.SOLVER.WARMUP_ITERS = 1000\n",
        "cfg.SOLVER.MAX_ITER = 2000\n",
        "cfg.SOLVER.STEPS = (1000, 1500)\n",
        "cfg.SOLVER.GAMMA = 0.05\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "\n",
        "cfg.TEST.EVAL_PERIOD = 500\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[10/08 06:24:47 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[10/08 06:24:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [Resize(shape=(400, 400)), RandomFlip(prob=0.5, horizontal=False, vertical=True), RandomSaturation(intensity_min=0.8, intensity_max=1.2), RandomBrightness(intensity_min=0.8, intensity_max=1.2), RandomContrast(intensity_min=0.8, intensity_max=1.2)]\n",
            "\u001b[32m[10/08 06:24:47 d2.data.datasets.coco]: \u001b[0mLoaded 12200 images in COCO format from /tf/datasets/final-dataset/detectron2-dataset/train/_annotations.coco.json\n",
            "\u001b[32m[10/08 06:24:47 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 12200 images left.\n",
            "\u001b[32m[10/08 06:24:47 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
            "\u001b[36m|   category    | #instances   |\n",
            "|:-------------:|:-------------|\n",
            "| license_plate | 12200        |\n",
            "|               |              |\u001b[0m\n",
            "\u001b[32m[10/08 06:24:47 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[10/08 06:24:47 d2.data.common]: \u001b[0mSerializing 12200 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[10/08 06:24:47 d2.data.common]: \u001b[0mSerialized dataset takes 3.00 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error in sys.excepthook:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.8/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 1936, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 1105, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 999, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 851, in structured_traceback\n",
            "    assert etb is not None\n",
            "AssertionError\n",
            "\n",
            "Original exception was:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.8/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[10/08 06:24:48 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[10/08 06:25:13 d2.utils.events]: \u001b[0m eta: 0:40:32  iter: 19  total_loss: 0.8043  loss_cls: 0.6663  loss_box_reg: 0.04169  loss_rpn_cls: 0.08693  loss_rpn_loc: 0.007043  time: 1.2210  data_time: 0.1905  lr: 1.931e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:25:38 d2.utils.events]: \u001b[0m eta: 0:39:38  iter: 39  total_loss: 0.7714  loss_cls: 0.6346  loss_box_reg: 0.04371  loss_rpn_cls: 0.08704  loss_rpn_loc: 0.007734  time: 1.2218  data_time: 0.1668  lr: 2.911e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:26:01 d2.utils.events]: \u001b[0m eta: 0:38:30  iter: 59  total_loss: 0.7228  loss_cls: 0.5747  loss_box_reg: 0.04906  loss_rpn_cls: 0.08758  loss_rpn_loc: 0.006913  time: 1.2042  data_time: 0.1100  lr: 3.891e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:26:25 d2.utils.events]: \u001b[0m eta: 0:38:11  iter: 79  total_loss: 0.6348  loss_cls: 0.4958  loss_box_reg: 0.04592  loss_rpn_cls: 0.09372  loss_rpn_loc: 0.00831  time: 1.2075  data_time: 0.1604  lr: 4.871e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:26:50 d2.utils.events]: \u001b[0m eta: 0:37:49  iter: 99  total_loss: 0.5617  loss_cls: 0.4242  loss_box_reg: 0.05406  loss_rpn_cls: 0.07618  loss_rpn_loc: 0.006293  time: 1.2070  data_time: 0.1371  lr: 5.851e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:27:13 d2.utils.events]: \u001b[0m eta: 0:37:16  iter: 119  total_loss: 0.5088  loss_cls: 0.3681  loss_box_reg: 0.04572  loss_rpn_cls: 0.08306  loss_rpn_loc: 0.007576  time: 1.2032  data_time: 0.1183  lr: 6.831e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:27:37 d2.utils.events]: \u001b[0m eta: 0:36:52  iter: 139  total_loss: 0.4572  loss_cls: 0.322  loss_box_reg: 0.0497  loss_rpn_cls: 0.07912  loss_rpn_loc: 0.007887  time: 1.2029  data_time: 0.1277  lr: 7.811e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:28:02 d2.utils.events]: \u001b[0m eta: 0:36:31  iter: 159  total_loss: 0.412  loss_cls: 0.2608  loss_box_reg: 0.05571  loss_rpn_cls: 0.07324  loss_rpn_loc: 0.007007  time: 1.2058  data_time: 0.1685  lr: 8.791e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:28:26 d2.utils.events]: \u001b[0m eta: 0:36:04  iter: 179  total_loss: 0.3726  loss_cls: 0.2281  loss_box_reg: 0.05779  loss_rpn_cls: 0.07175  loss_rpn_loc: 0.007714  time: 1.2047  data_time: 0.1455  lr: 9.771e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:28:50 d2.utils.events]: \u001b[0m eta: 0:35:41  iter: 199  total_loss: 0.3368  loss_cls: 0.1982  loss_box_reg: 0.06322  loss_rpn_cls: 0.06358  loss_rpn_loc: 0.007421  time: 1.2034  data_time: 0.1326  lr: 1.0751e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:29:13 d2.utils.events]: \u001b[0m eta: 0:35:16  iter: 219  total_loss: 0.3155  loss_cls: 0.1771  loss_box_reg: 0.06299  loss_rpn_cls: 0.06776  loss_rpn_loc: 0.007427  time: 1.2000  data_time: 0.1149  lr: 1.1731e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:29:38 d2.utils.events]: \u001b[0m eta: 0:34:55  iter: 239  total_loss: 0.2965  loss_cls: 0.1622  loss_box_reg: 0.06804  loss_rpn_cls: 0.05193  loss_rpn_loc: 0.006594  time: 1.2024  data_time: 0.1481  lr: 1.2711e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:30:02 d2.utils.events]: \u001b[0m eta: 0:34:34  iter: 259  total_loss: 0.281  loss_cls: 0.1492  loss_box_reg: 0.07211  loss_rpn_cls: 0.05101  loss_rpn_loc: 0.006006  time: 1.2045  data_time: 0.1490  lr: 1.3691e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:30:27 d2.utils.events]: \u001b[0m eta: 0:34:11  iter: 279  total_loss: 0.2752  loss_cls: 0.1417  loss_box_reg: 0.07878  loss_rpn_cls: 0.05283  loss_rpn_loc: 0.00629  time: 1.2070  data_time: 0.1654  lr: 1.4671e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:30:51 d2.utils.events]: \u001b[0m eta: 0:33:50  iter: 299  total_loss: 0.2595  loss_cls: 0.1295  loss_box_reg: 0.07502  loss_rpn_cls: 0.04125  loss_rpn_loc: 0.006458  time: 1.2076  data_time: 0.1466  lr: 1.5651e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:31:15 d2.utils.events]: \u001b[0m eta: 0:33:25  iter: 319  total_loss: 0.251  loss_cls: 0.1242  loss_box_reg: 0.07711  loss_rpn_cls: 0.03605  loss_rpn_loc: 0.00615  time: 1.2063  data_time: 0.1280  lr: 1.6631e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:31:40 d2.utils.events]: \u001b[0m eta: 0:33:03  iter: 339  total_loss: 0.253  loss_cls: 0.1247  loss_box_reg: 0.08847  loss_rpn_cls: 0.03864  loss_rpn_loc: 0.005732  time: 1.2075  data_time: 0.1749  lr: 1.7611e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:32:03 d2.utils.events]: \u001b[0m eta: 0:32:35  iter: 359  total_loss: 0.254  loss_cls: 0.1231  loss_box_reg: 0.09029  loss_rpn_cls: 0.03667  loss_rpn_loc: 0.005627  time: 1.2055  data_time: 0.1158  lr: 1.8591e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:32:27 d2.utils.events]: \u001b[0m eta: 0:32:11  iter: 379  total_loss: 0.2593  loss_cls: 0.1155  loss_box_reg: 0.08682  loss_rpn_cls: 0.04106  loss_rpn_loc: 0.007495  time: 1.2051  data_time: 0.1516  lr: 1.9571e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:32:50 d2.utils.events]: \u001b[0m eta: 0:31:42  iter: 399  total_loss: 0.2562  loss_cls: 0.1171  loss_box_reg: 0.09306  loss_rpn_cls: 0.03349  loss_rpn_loc: 0.005896  time: 1.2029  data_time: 0.0977  lr: 2.0551e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:33:14 d2.utils.events]: \u001b[0m eta: 0:31:21  iter: 419  total_loss: 0.2524  loss_cls: 0.1133  loss_box_reg: 0.09565  loss_rpn_cls: 0.03137  loss_rpn_loc: 0.006695  time: 1.2032  data_time: 0.1337  lr: 2.1531e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:33:38 d2.utils.events]: \u001b[0m eta: 0:30:57  iter: 439  total_loss: 0.2465  loss_cls: 0.1117  loss_box_reg: 0.09644  loss_rpn_cls: 0.03228  loss_rpn_loc: 0.005756  time: 1.2029  data_time: 0.1485  lr: 2.2511e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:34:01 d2.utils.events]: \u001b[0m eta: 0:30:30  iter: 459  total_loss: 0.248  loss_cls: 0.1117  loss_box_reg: 0.1064  loss_rpn_cls: 0.02348  loss_rpn_loc: 0.005995  time: 1.2004  data_time: 0.1087  lr: 2.3491e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:34:25 d2.utils.events]: \u001b[0m eta: 0:30:06  iter: 479  total_loss: 0.2482  loss_cls: 0.109  loss_box_reg: 0.1056  loss_rpn_cls: 0.02099  loss_rpn_loc: 0.005203  time: 1.2000  data_time: 0.1520  lr: 2.4471e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:34:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [Resize(shape=(400, 400))]\n",
            "\u001b[32m[10/08 06:34:48 d2.data.datasets.coco]: \u001b[0mLoaded 1435 images in COCO format from /tf/datasets/final-dataset/detectron2-dataset/val/_annotations.coco.json\n",
            "\u001b[32m[10/08 06:34:48 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
            "\u001b[36m|   category    | #instances   |\n",
            "|:-------------:|:-------------|\n",
            "| license_plate | 1435         |\n",
            "|               |              |\u001b[0m\n",
            "\u001b[32m[10/08 06:34:48 d2.data.common]: \u001b[0mSerializing 1435 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[10/08 06:34:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[10/08 06:34:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 1435 batches\n",
            "\u001b[32m[10/08 06:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/1435. Dataloading: 0.0003 s/iter. Inference: 0.0447 s/iter. Eval: 0.0002 s/iter. Total: 0.0451 s/iter. ETA=0:01:04\n",
            "\u001b[32m[10/08 06:34:54 d2.evaluation.evaluator]: \u001b[0mInference done 109/1435. Dataloading: 0.0024 s/iter. Inference: 0.0483 s/iter. Eval: 0.0002 s/iter. Total: 0.0510 s/iter. ETA=0:01:07\n",
            "\u001b[32m[10/08 06:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 209/1435. Dataloading: 0.0028 s/iter. Inference: 0.0475 s/iter. Eval: 0.0002 s/iter. Total: 0.0506 s/iter. ETA=0:01:02\n",
            "\u001b[32m[10/08 06:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 312/1435. Dataloading: 0.0026 s/iter. Inference: 0.0472 s/iter. Eval: 0.0002 s/iter. Total: 0.0500 s/iter. ETA=0:00:56\n",
            "\u001b[32m[10/08 06:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 426/1435. Dataloading: 0.0021 s/iter. Inference: 0.0460 s/iter. Eval: 0.0002 s/iter. Total: 0.0484 s/iter. ETA=0:00:48\n",
            "\u001b[32m[10/08 06:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 535/1435. Dataloading: 0.0018 s/iter. Inference: 0.0458 s/iter. Eval: 0.0002 s/iter. Total: 0.0479 s/iter. ETA=0:00:43\n",
            "\u001b[32m[10/08 06:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 648/1435. Dataloading: 0.0017 s/iter. Inference: 0.0454 s/iter. Eval: 0.0002 s/iter. Total: 0.0473 s/iter. ETA=0:00:37\n",
            "\u001b[32m[10/08 06:35:24 d2.evaluation.evaluator]: \u001b[0mInference done 775/1435. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:00:30\n",
            "\u001b[32m[10/08 06:35:29 d2.evaluation.evaluator]: \u001b[0mInference done 892/1435. Dataloading: 0.0014 s/iter. Inference: 0.0439 s/iter. Eval: 0.0002 s/iter. Total: 0.0456 s/iter. ETA=0:00:24\n",
            "\u001b[32m[10/08 06:35:34 d2.evaluation.evaluator]: \u001b[0mInference done 1011/1435. Dataloading: 0.0013 s/iter. Inference: 0.0436 s/iter. Eval: 0.0002 s/iter. Total: 0.0452 s/iter. ETA=0:00:19\n",
            "\u001b[32m[10/08 06:35:39 d2.evaluation.evaluator]: \u001b[0mInference done 1118/1435. Dataloading: 0.0013 s/iter. Inference: 0.0438 s/iter. Eval: 0.0002 s/iter. Total: 0.0454 s/iter. ETA=0:00:14\n",
            "\u001b[32m[10/08 06:35:44 d2.evaluation.evaluator]: \u001b[0mInference done 1237/1435. Dataloading: 0.0012 s/iter. Inference: 0.0436 s/iter. Eval: 0.0002 s/iter. Total: 0.0451 s/iter. ETA=0:00:08\n",
            "\u001b[32m[10/08 06:35:49 d2.evaluation.evaluator]: \u001b[0mInference done 1349/1435. Dataloading: 0.0012 s/iter. Inference: 0.0436 s/iter. Eval: 0.0002 s/iter. Total: 0.0450 s/iter. ETA=0:00:03\n",
            "\u001b[32m[10/08 06:35:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:04.285421 (0.044955 s / iter per device, on 1 devices)\n",
            "\u001b[32m[10/08 06:35:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:02 (0.043482 s / iter per device, on 1 devices)\n",
            "\u001b[32m[10/08 06:35:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[10/08 06:35:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[10/08 06:35:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[10/08 06:35:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[10/08 06:35:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.36 seconds.\n",
            "\u001b[32m[10/08 06:35:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[10/08 06:35:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.14 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.589\n",
            "\u001b[32m[10/08 06:35:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.531 | 5.262  | 1.937  | 0.141 | 3.652 | 3.085 |\n",
            "\u001b[32m[10/08 06:35:54 d2.engine.defaults]: \u001b[0mEvaluation results for custom_dataset_val in csv format:\n",
            "\u001b[32m[10/08 06:35:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[10/08 06:35:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[10/08 06:35:54 d2.evaluation.testing]: \u001b[0mcopypaste: 2.5311,5.2620,1.9366,0.1413,3.6520,3.0847\n",
            "\u001b[32m[10/08 06:35:54 d2.utils.events]: \u001b[0m eta: 0:29:41  iter: 499  total_loss: 0.2519  loss_cls: 0.1084  loss_box_reg: 0.1049  loss_rpn_cls: 0.02362  loss_rpn_loc: 0.005727  time: 1.1983  data_time: 0.1146  lr: 2.5451e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:36:19 d2.utils.events]: \u001b[0m eta: 0:29:18  iter: 519  total_loss: 0.2419  loss_cls: 0.1058  loss_box_reg: 0.1097  loss_rpn_cls: 0.02064  loss_rpn_loc: 0.005539  time: 1.1996  data_time: 0.1608  lr: 2.6431e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:36:44 d2.utils.events]: \u001b[0m eta: 0:28:56  iter: 539  total_loss: 0.2472  loss_cls: 0.1033  loss_box_reg: 0.1076  loss_rpn_cls: 0.02506  loss_rpn_loc: 0.006299  time: 1.2005  data_time: 0.1485  lr: 2.7411e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:37:08 d2.utils.events]: \u001b[0m eta: 0:28:33  iter: 559  total_loss: 0.2355  loss_cls: 0.1002  loss_box_reg: 0.1055  loss_rpn_cls: 0.01982  loss_rpn_loc: 0.00574  time: 1.2021  data_time: 0.1604  lr: 2.8391e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:37:33 d2.utils.events]: \u001b[0m eta: 0:28:11  iter: 579  total_loss: 0.2415  loss_cls: 0.1009  loss_box_reg: 0.1148  loss_rpn_cls: 0.0189  loss_rpn_loc: 0.00548  time: 1.2027  data_time: 0.1509  lr: 2.9371e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:37:57 d2.utils.events]: \u001b[0m eta: 0:27:48  iter: 599  total_loss: 0.2421  loss_cls: 0.09935  loss_box_reg: 0.1198  loss_rpn_cls: 0.01741  loss_rpn_loc: 0.00483  time: 1.2032  data_time: 0.1357  lr: 3.0351e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:38:21 d2.utils.events]: \u001b[0m eta: 0:27:24  iter: 619  total_loss: 0.2375  loss_cls: 0.09814  loss_box_reg: 0.1161  loss_rpn_cls: 0.01842  loss_rpn_loc: 0.005374  time: 1.2029  data_time: 0.1240  lr: 3.1331e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:38:46 d2.utils.events]: \u001b[0m eta: 0:27:00  iter: 639  total_loss: 0.2381  loss_cls: 0.09535  loss_box_reg: 0.1149  loss_rpn_cls: 0.0218  loss_rpn_loc: 0.005842  time: 1.2043  data_time: 0.1765  lr: 3.2311e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:39:10 d2.utils.events]: \u001b[0m eta: 0:26:36  iter: 659  total_loss: 0.2389  loss_cls: 0.09567  loss_box_reg: 0.1171  loss_rpn_cls: 0.01894  loss_rpn_loc: 0.005976  time: 1.2042  data_time: 0.1386  lr: 3.3291e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:39:35 d2.utils.events]: \u001b[0m eta: 0:26:12  iter: 679  total_loss: 0.2321  loss_cls: 0.09195  loss_box_reg: 0.1156  loss_rpn_cls: 0.01774  loss_rpn_loc: 0.005061  time: 1.2047  data_time: 0.1620  lr: 3.4271e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:39:58 d2.utils.events]: \u001b[0m eta: 0:25:49  iter: 699  total_loss: 0.2333  loss_cls: 0.09197  loss_box_reg: 0.118  loss_rpn_cls: 0.0164  loss_rpn_loc: 0.005564  time: 1.2044  data_time: 0.1355  lr: 3.5251e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:40:22 d2.utils.events]: \u001b[0m eta: 0:25:24  iter: 719  total_loss: 0.2271  loss_cls: 0.08766  loss_box_reg: 0.114  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.005941  time: 1.2037  data_time: 0.1299  lr: 3.6231e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:40:45 d2.utils.events]: \u001b[0m eta: 0:25:00  iter: 739  total_loss: 0.2302  loss_cls: 0.08748  loss_box_reg: 0.1197  loss_rpn_cls: 0.01659  loss_rpn_loc: 0.004928  time: 1.2027  data_time: 0.1288  lr: 3.7211e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:41:09 d2.utils.events]: \u001b[0m eta: 0:24:36  iter: 759  total_loss: 0.2278  loss_cls: 0.08451  loss_box_reg: 0.1136  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.005835  time: 1.2024  data_time: 0.1476  lr: 3.8191e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:41:33 d2.utils.events]: \u001b[0m eta: 0:24:11  iter: 779  total_loss: 0.2367  loss_cls: 0.08708  loss_box_reg: 0.1276  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.004865  time: 1.2016  data_time: 0.1217  lr: 3.9171e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:41:57 d2.utils.events]: \u001b[0m eta: 0:23:48  iter: 799  total_loss: 0.2279  loss_cls: 0.08215  loss_box_reg: 0.1209  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.004745  time: 1.2019  data_time: 0.1545  lr: 4.0151e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:42:20 d2.utils.events]: \u001b[0m eta: 0:23:23  iter: 819  total_loss: 0.2193  loss_cls: 0.08118  loss_box_reg: 0.1155  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.005092  time: 1.2010  data_time: 0.1421  lr: 4.1131e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:42:44 d2.utils.events]: \u001b[0m eta: 0:22:59  iter: 839  total_loss: 0.2262  loss_cls: 0.08259  loss_box_reg: 0.1252  loss_rpn_cls: 0.01243  loss_rpn_loc: 0.005113  time: 1.2002  data_time: 0.1412  lr: 4.2111e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:43:07 d2.utils.events]: \u001b[0m eta: 0:22:35  iter: 859  total_loss: 0.2227  loss_cls: 0.07981  loss_box_reg: 0.1232  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.006559  time: 1.1992  data_time: 0.1317  lr: 4.3091e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:43:30 d2.utils.events]: \u001b[0m eta: 0:22:10  iter: 879  total_loss: 0.2285  loss_cls: 0.08138  loss_box_reg: 0.1281  loss_rpn_cls: 0.01146  loss_rpn_loc: 0.005485  time: 1.1983  data_time: 0.1294  lr: 4.4071e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:43:53 d2.utils.events]: \u001b[0m eta: 0:21:46  iter: 899  total_loss: 0.2221  loss_cls: 0.07945  loss_box_reg: 0.1252  loss_rpn_cls: 0.01122  loss_rpn_loc: 0.004583  time: 1.1973  data_time: 0.1229  lr: 4.5051e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:44:16 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 919  total_loss: 0.2269  loss_cls: 0.07813  loss_box_reg: 0.1244  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.004891  time: 1.1965  data_time: 0.1266  lr: 4.6031e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:44:39 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 939  total_loss: 0.2181  loss_cls: 0.07532  loss_box_reg: 0.1257  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.00486  time: 1.1956  data_time: 0.1199  lr: 4.7011e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:45:03 d2.utils.events]: \u001b[0m eta: 0:20:32  iter: 959  total_loss: 0.2186  loss_cls: 0.07528  loss_box_reg: 0.1273  loss_rpn_cls: 0.008948  loss_rpn_loc: 0.005862  time: 1.1951  data_time: 0.1497  lr: 4.7991e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:45:26 d2.utils.events]: \u001b[0m eta: 0:20:07  iter: 979  total_loss: 0.2246  loss_cls: 0.07658  loss_box_reg: 0.1331  loss_rpn_cls: 0.009561  loss_rpn_loc: 0.005034  time: 1.1940  data_time: 0.1123  lr: 4.8971e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:45:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [Resize(shape=(400, 400))]\n",
            "\u001b[32m[10/08 06:45:49 d2.data.datasets.coco]: \u001b[0mLoaded 1435 images in COCO format from /tf/datasets/final-dataset/detectron2-dataset/val/_annotations.coco.json\n",
            "\u001b[32m[10/08 06:45:49 d2.data.common]: \u001b[0mSerializing 1435 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[10/08 06:45:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[10/08 06:45:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 1435 batches\n",
            "\u001b[32m[10/08 06:45:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/1435. Dataloading: 0.0003 s/iter. Inference: 0.0429 s/iter. Eval: 0.0002 s/iter. Total: 0.0434 s/iter. ETA=0:01:01\n",
            "\u001b[32m[10/08 06:45:55 d2.evaluation.evaluator]: \u001b[0mInference done 111/1435. Dataloading: 0.0026 s/iter. Inference: 0.0469 s/iter. Eval: 0.0002 s/iter. Total: 0.0497 s/iter. ETA=0:01:05\n",
            "\u001b[32m[10/08 06:46:00 d2.evaluation.evaluator]: \u001b[0mInference done 215/1435. Dataloading: 0.0028 s/iter. Inference: 0.0461 s/iter. Eval: 0.0002 s/iter. Total: 0.0491 s/iter. ETA=0:00:59\n",
            "\u001b[32m[10/08 06:46:05 d2.evaluation.evaluator]: \u001b[0mInference done 323/1435. Dataloading: 0.0025 s/iter. Inference: 0.0456 s/iter. Eval: 0.0002 s/iter. Total: 0.0483 s/iter. ETA=0:00:53\n",
            "\u001b[32m[10/08 06:46:10 d2.evaluation.evaluator]: \u001b[0mInference done 437/1435. Dataloading: 0.0021 s/iter. Inference: 0.0448 s/iter. Eval: 0.0002 s/iter. Total: 0.0471 s/iter. ETA=0:00:47\n",
            "\u001b[32m[10/08 06:46:15 d2.evaluation.evaluator]: \u001b[0mInference done 545/1435. Dataloading: 0.0018 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:00:41\n",
            "\u001b[32m[10/08 06:46:20 d2.evaluation.evaluator]: \u001b[0mInference done 660/1435. Dataloading: 0.0016 s/iter. Inference: 0.0446 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:00:35\n",
            "\u001b[32m[10/08 06:46:25 d2.evaluation.evaluator]: \u001b[0mInference done 783/1435. Dataloading: 0.0015 s/iter. Inference: 0.0438 s/iter. Eval: 0.0002 s/iter. Total: 0.0456 s/iter. ETA=0:00:29\n",
            "\u001b[32m[10/08 06:46:30 d2.evaluation.evaluator]: \u001b[0mInference done 907/1435. Dataloading: 0.0014 s/iter. Inference: 0.0433 s/iter. Eval: 0.0002 s/iter. Total: 0.0449 s/iter. ETA=0:00:23\n",
            "\u001b[32m[10/08 06:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 1032/1435. Dataloading: 0.0013 s/iter. Inference: 0.0427 s/iter. Eval: 0.0002 s/iter. Total: 0.0443 s/iter. ETA=0:00:17\n",
            "\u001b[32m[10/08 06:46:40 d2.evaluation.evaluator]: \u001b[0mInference done 1153/1435. Dataloading: 0.0013 s/iter. Inference: 0.0425 s/iter. Eval: 0.0002 s/iter. Total: 0.0440 s/iter. ETA=0:00:12\n",
            "\u001b[32m[10/08 06:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 1275/1435. Dataloading: 0.0012 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0437 s/iter. ETA=0:00:06\n",
            "\u001b[32m[10/08 06:46:50 d2.evaluation.evaluator]: \u001b[0mInference done 1397/1435. Dataloading: 0.0012 s/iter. Inference: 0.0421 s/iter. Eval: 0.0002 s/iter. Total: 0.0435 s/iter. ETA=0:00:01\n",
            "\u001b[32m[10/08 06:46:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:02.107055 (0.043432 s / iter per device, on 1 devices)\n",
            "\u001b[32m[10/08 06:46:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:00 (0.041980 s / iter per device, on 1 devices)\n",
            "\u001b[32m[10/08 06:46:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[10/08 06:46:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[10/08 06:46:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[10/08 06:46:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[10/08 06:46:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.23 seconds.\n",
            "\u001b[32m[10/08 06:46:53 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[10/08 06:46:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.667\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.385\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.432\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.560\n",
            "\u001b[32m[10/08 06:46:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 31.468 | 66.659 | 20.596 | 3.481 | 31.571 | 38.493 |\n",
            "\u001b[32m[10/08 06:46:53 d2.engine.defaults]: \u001b[0mEvaluation results for custom_dataset_val in csv format:\n",
            "\u001b[32m[10/08 06:46:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[10/08 06:46:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[10/08 06:46:53 d2.evaluation.testing]: \u001b[0mcopypaste: 31.4675,66.6591,20.5963,3.4806,31.5711,38.4928\n",
            "\u001b[32m[10/08 06:46:53 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 999  total_loss: 0.2205  loss_cls: 0.07445  loss_box_reg: 0.1281  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.003985  time: 1.1938  data_time: 0.1444  lr: 4.9951e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:47:16 d2.utils.events]: \u001b[0m eta: 0:19:19  iter: 1019  total_loss: 0.2125  loss_cls: 0.07252  loss_box_reg: 0.1253  loss_rpn_cls: 0.009573  loss_rpn_loc: 0.005493  time: 1.1928  data_time: 0.1476  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:47:38 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 1039  total_loss: 0.2193  loss_cls: 0.0733  loss_box_reg: 0.1294  loss_rpn_cls: 0.01136  loss_rpn_loc: 0.004923  time: 1.1911  data_time: 0.1446  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:47:59 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 1059  total_loss: 0.2189  loss_cls: 0.0699  loss_box_reg: 0.1213  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.00445  time: 1.1888  data_time: 0.1209  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:48:21 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 1079  total_loss: 0.2116  loss_cls: 0.06887  loss_box_reg: 0.1241  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.004445  time: 1.1870  data_time: 0.1363  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:48:43 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 1099  total_loss: 0.21  loss_cls: 0.0686  loss_box_reg: 0.128  loss_rpn_cls: 0.007537  loss_rpn_loc: 0.004151  time: 1.1854  data_time: 0.1399  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:49:05 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 1119  total_loss: 0.2103  loss_cls: 0.06914  loss_box_reg: 0.1248  loss_rpn_cls: 0.01596  loss_rpn_loc: 0.005134  time: 1.1839  data_time: 0.1513  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:49:27 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 1139  total_loss: 0.2009  loss_cls: 0.06595  loss_box_reg: 0.1168  loss_rpn_cls: 0.009407  loss_rpn_loc: 0.00403  time: 1.1823  data_time: 0.1436  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:49:49 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 1159  total_loss: 0.2118  loss_cls: 0.06803  loss_box_reg: 0.1279  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.004298  time: 1.1807  data_time: 0.1384  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:50:10 d2.utils.events]: \u001b[0m eta: 0:15:57  iter: 1179  total_loss: 0.2099  loss_cls: 0.06677  loss_box_reg: 0.131  loss_rpn_cls: 0.009104  loss_rpn_loc: 0.004807  time: 1.1788  data_time: 0.1185  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:50:32 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 1199  total_loss: 0.2012  loss_cls: 0.06363  loss_box_reg: 0.1221  loss_rpn_cls: 0.007633  loss_rpn_loc: 0.004297  time: 1.1773  data_time: 0.1377  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:50:53 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 1219  total_loss: 0.1985  loss_cls: 0.06209  loss_box_reg: 0.1201  loss_rpn_cls: 0.007389  loss_rpn_loc: 0.003913  time: 1.1753  data_time: 0.1098  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:51:15 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 1239  total_loss: 0.2027  loss_cls: 0.06291  loss_box_reg: 0.1222  loss_rpn_cls: 0.008994  loss_rpn_loc: 0.004376  time: 1.1743  data_time: 0.1558  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:51:37 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 1259  total_loss: 0.2038  loss_cls: 0.06186  loss_box_reg: 0.125  loss_rpn_cls: 0.008267  loss_rpn_loc: 0.004833  time: 1.1729  data_time: 0.1411  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:51:59 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 1279  total_loss: 0.1987  loss_cls: 0.06313  loss_box_reg: 0.1209  loss_rpn_cls: 0.008554  loss_rpn_loc: 0.004668  time: 1.1714  data_time: 0.1165  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:52:21 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 1299  total_loss: 0.1991  loss_cls: 0.06105  loss_box_reg: 0.1234  loss_rpn_cls: 0.007111  loss_rpn_loc: 0.004347  time: 1.1703  data_time: 0.1576  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:52:43 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 1319  total_loss: 0.1956  loss_cls: 0.05975  loss_box_reg: 0.1181  loss_rpn_cls: 0.009628  loss_rpn_loc: 0.004279  time: 1.1692  data_time: 0.1432  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:53:04 d2.utils.events]: \u001b[0m eta: 0:12:39  iter: 1339  total_loss: 0.1979  loss_cls: 0.05868  loss_box_reg: 0.1203  loss_rpn_cls: 0.008427  loss_rpn_loc: 0.004496  time: 1.1680  data_time: 0.1394  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:53:25 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 1359  total_loss: 0.1973  loss_cls: 0.05979  loss_box_reg: 0.1232  loss_rpn_cls: 0.009304  loss_rpn_loc: 0.003996  time: 1.1664  data_time: 0.1099  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:53:47 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 1379  total_loss: 0.1965  loss_cls: 0.05746  loss_box_reg: 0.1154  loss_rpn_cls: 0.009323  loss_rpn_loc: 0.005039  time: 1.1649  data_time: 0.1212  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:54:08 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 1399  total_loss: 0.1965  loss_cls: 0.05774  loss_box_reg: 0.1214  loss_rpn_cls: 0.006362  loss_rpn_loc: 0.0044  time: 1.1636  data_time: 0.1223  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:54:30 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 1419  total_loss: 0.1912  loss_cls: 0.05699  loss_box_reg: 0.1172  loss_rpn_cls: 0.007165  loss_rpn_loc: 0.004414  time: 1.1622  data_time: 0.1167  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:54:51 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 1439  total_loss: 0.1983  loss_cls: 0.05975  loss_box_reg: 0.1223  loss_rpn_cls: 0.008865  loss_rpn_loc: 0.004584  time: 1.1609  data_time: 0.1239  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:55:13 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 1459  total_loss: 0.1874  loss_cls: 0.05493  loss_box_reg: 0.1167  loss_rpn_cls: 0.006617  loss_rpn_loc: 0.004115  time: 1.1598  data_time: 0.1368  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:55:34 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 1479  total_loss: 0.1883  loss_cls: 0.05641  loss_box_reg: 0.1134  loss_rpn_cls: 0.009932  loss_rpn_loc: 0.004772  time: 1.1589  data_time: 0.1515  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:55:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [Resize(shape=(400, 400))]\n",
            "\u001b[32m[10/08 06:55:56 d2.data.datasets.coco]: \u001b[0mLoaded 1435 images in COCO format from /tf/datasets/final-dataset/detectron2-dataset/val/_annotations.coco.json\n",
            "\u001b[32m[10/08 06:55:56 d2.data.common]: \u001b[0mSerializing 1435 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[10/08 06:55:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[10/08 06:55:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 1435 batches\n",
            "\u001b[32m[10/08 06:55:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/1435. Dataloading: 0.0004 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:59\n",
            "\u001b[32m[10/08 06:56:02 d2.evaluation.evaluator]: \u001b[0mInference done 120/1435. Dataloading: 0.0033 s/iter. Inference: 0.0424 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:01:00\n",
            "\u001b[32m[10/08 06:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 230/1435. Dataloading: 0.0034 s/iter. Inference: 0.0422 s/iter. Eval: 0.0002 s/iter. Total: 0.0458 s/iter. ETA=0:00:55\n",
            "\u001b[32m[10/08 06:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 346/1435. Dataloading: 0.0028 s/iter. Inference: 0.0420 s/iter. Eval: 0.0002 s/iter. Total: 0.0450 s/iter. ETA=0:00:49\n",
            "\u001b[32m[10/08 06:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 467/1435. Dataloading: 0.0023 s/iter. Inference: 0.0416 s/iter. Eval: 0.0002 s/iter. Total: 0.0441 s/iter. ETA=0:00:42\n",
            "\u001b[32m[10/08 06:56:22 d2.evaluation.evaluator]: \u001b[0mInference done 577/1435. Dataloading: 0.0020 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0444 s/iter. ETA=0:00:38\n",
            "\u001b[32m[10/08 06:56:27 d2.evaluation.evaluator]: \u001b[0mInference done 706/1435. Dataloading: 0.0018 s/iter. Inference: 0.0415 s/iter. Eval: 0.0002 s/iter. Total: 0.0434 s/iter. ETA=0:00:31\n",
            "\u001b[32m[10/08 06:56:32 d2.evaluation.evaluator]: \u001b[0mInference done 835/1435. Dataloading: 0.0016 s/iter. Inference: 0.0409 s/iter. Eval: 0.0002 s/iter. Total: 0.0427 s/iter. ETA=0:00:25\n",
            "\u001b[32m[10/08 06:56:37 d2.evaluation.evaluator]: \u001b[0mInference done 966/1435. Dataloading: 0.0015 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:00:19\n",
            "\u001b[32m[10/08 06:56:42 d2.evaluation.evaluator]: \u001b[0mInference done 1099/1435. Dataloading: 0.0014 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:13\n",
            "\u001b[32m[10/08 06:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 1228/1435. Dataloading: 0.0013 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:08\n",
            "\u001b[32m[10/08 06:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 1357/1435. Dataloading: 0.0013 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:03\n",
            "\u001b[32m[10/08 06:56:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:58.721709 (0.041064 s / iter per device, on 1 devices)\n",
            "\u001b[32m[10/08 06:56:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:56 (0.039558 s / iter per device, on 1 devices)\n",
            "\u001b[32m[10/08 06:56:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[10/08 06:56:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[10/08 06:56:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[10/08 06:56:55 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[10/08 06:56:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
            "\u001b[32m[10/08 06:56:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[10/08 06:56:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.779\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.560\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567\n",
            "\u001b[32m[10/08 06:56:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 38.357 | 77.873 | 27.094 | 6.491 | 38.978 | 44.621 |\n",
            "\u001b[32m[10/08 06:56:56 d2.engine.defaults]: \u001b[0mEvaluation results for custom_dataset_val in csv format:\n",
            "\u001b[32m[10/08 06:56:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[10/08 06:56:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[10/08 06:56:56 d2.evaluation.testing]: \u001b[0mcopypaste: 38.3569,77.8731,27.0935,6.4908,38.9782,44.6205\n",
            "\u001b[32m[10/08 06:56:56 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 1499  total_loss: 0.1777  loss_cls: 0.05399  loss_box_reg: 0.1076  loss_rpn_cls: 0.008292  loss_rpn_loc: 0.004356  time: 1.1578  data_time: 0.1335  lr: 5e-05  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:57:18 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 1519  total_loss: 0.1786  loss_cls: 0.0533  loss_box_reg: 0.1063  loss_rpn_cls: 0.007667  loss_rpn_loc: 0.004438  time: 1.1569  data_time: 0.1485  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:57:39 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 1539  total_loss: 0.1792  loss_cls: 0.05375  loss_box_reg: 0.1075  loss_rpn_cls: 0.009713  loss_rpn_loc: 0.004499  time: 1.1559  data_time: 0.1314  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:58:01 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 1559  total_loss: 0.1848  loss_cls: 0.05595  loss_box_reg: 0.1132  loss_rpn_cls: 0.007733  loss_rpn_loc: 0.00497  time: 1.1551  data_time: 0.1432  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:58:23 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 1579  total_loss: 0.1832  loss_cls: 0.05408  loss_box_reg: 0.1157  loss_rpn_cls: 0.008388  loss_rpn_loc: 0.004394  time: 1.1541  data_time: 0.1320  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:58:44 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 1599  total_loss: 0.1797  loss_cls: 0.05321  loss_box_reg: 0.1155  loss_rpn_cls: 0.005671  loss_rpn_loc: 0.004024  time: 1.1530  data_time: 0.1182  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:59:06 d2.utils.events]: \u001b[0m eta: 0:07:03  iter: 1619  total_loss: 0.1778  loss_cls: 0.05178  loss_box_reg: 0.1113  loss_rpn_cls: 0.005178  loss_rpn_loc: 0.004038  time: 1.1523  data_time: 0.1501  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:59:27 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 1639  total_loss: 0.1909  loss_cls: 0.05657  loss_box_reg: 0.114  loss_rpn_cls: 0.007506  loss_rpn_loc: 0.003985  time: 1.1513  data_time: 0.1235  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 06:59:49 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 1659  total_loss: 0.1921  loss_cls: 0.05708  loss_box_reg: 0.1135  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.005368  time: 1.1505  data_time: 0.1478  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:00:11 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 1679  total_loss: 0.1828  loss_cls: 0.05299  loss_box_reg: 0.1101  loss_rpn_cls: 0.006164  loss_rpn_loc: 0.004241  time: 1.1500  data_time: 0.1612  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:00:33 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 1699  total_loss: 0.1775  loss_cls: 0.05299  loss_box_reg: 0.1111  loss_rpn_cls: 0.008345  loss_rpn_loc: 0.004409  time: 1.1491  data_time: 0.1261  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:00:55 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 1719  total_loss: 0.1811  loss_cls: 0.05481  loss_box_reg: 0.111  loss_rpn_cls: 0.006103  loss_rpn_loc: 0.003827  time: 1.1484  data_time: 0.1497  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:01:16 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 1739  total_loss: 0.1774  loss_cls: 0.05351  loss_box_reg: 0.1081  loss_rpn_cls: 0.005943  loss_rpn_loc: 0.004074  time: 1.1474  data_time: 0.1264  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:01:37 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 1759  total_loss: 0.1785  loss_cls: 0.05514  loss_box_reg: 0.1059  loss_rpn_cls: 0.009083  loss_rpn_loc: 0.004542  time: 1.1464  data_time: 0.1165  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:01:59 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 1779  total_loss: 0.1822  loss_cls: 0.05463  loss_box_reg: 0.1134  loss_rpn_cls: 0.007926  loss_rpn_loc: 0.004842  time: 1.1457  data_time: 0.1373  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:02:20 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 1799  total_loss: 0.1778  loss_cls: 0.05377  loss_box_reg: 0.1105  loss_rpn_cls: 0.005996  loss_rpn_loc: 0.004061  time: 1.1447  data_time: 0.1150  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:02:41 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 1819  total_loss: 0.1777  loss_cls: 0.05416  loss_box_reg: 0.1148  loss_rpn_cls: 0.004701  loss_rpn_loc: 0.004128  time: 1.1440  data_time: 0.1376  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:03:03 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 1839  total_loss: 0.1856  loss_cls: 0.05478  loss_box_reg: 0.1145  loss_rpn_cls: 0.006857  loss_rpn_loc: 0.004003  time: 1.1434  data_time: 0.1424  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:03:25 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 1859  total_loss: 0.1798  loss_cls: 0.05592  loss_box_reg: 0.1125  loss_rpn_cls: 0.006552  loss_rpn_loc: 0.004271  time: 1.1428  data_time: 0.1576  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:03:47 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 1879  total_loss: 0.1799  loss_cls: 0.05406  loss_box_reg: 0.1105  loss_rpn_cls: 0.006664  loss_rpn_loc: 0.003873  time: 1.1422  data_time: 0.1416  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:04:08 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 1899  total_loss: 0.1791  loss_cls: 0.05257  loss_box_reg: 0.1132  loss_rpn_cls: 0.006578  loss_rpn_loc: 0.004576  time: 1.1413  data_time: 0.1104  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:04:29 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 1919  total_loss: 0.1786  loss_cls: 0.05201  loss_box_reg: 0.1141  loss_rpn_cls: 0.008289  loss_rpn_loc: 0.004402  time: 1.1406  data_time: 0.1371  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:04:51 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 1939  total_loss: 0.1776  loss_cls: 0.05323  loss_box_reg: 0.1099  loss_rpn_cls: 0.008233  loss_rpn_loc: 0.004633  time: 1.1401  data_time: 0.1362  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:05:13 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 1959  total_loss: 0.176  loss_cls: 0.05136  loss_box_reg: 0.1097  loss_rpn_cls: 0.007015  loss_rpn_loc: 0.004175  time: 1.1395  data_time: 0.1371  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:05:35 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 1979  total_loss: 0.1722  loss_cls: 0.05294  loss_box_reg: 0.1084  loss_rpn_cls: 0.005628  loss_rpn_loc: 0.00424  time: 1.1392  data_time: 0.1703  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:05:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1999  total_loss: 0.1779  loss_cls: 0.05193  loss_box_reg: 0.1137  loss_rpn_cls: 0.006078  loss_rpn_loc: 0.003958  time: 1.1390  data_time: 0.1688  lr: 2.5e-06  max_mem: 4667M\n",
            "\u001b[32m[10/08 07:05:58 d2.engine.hooks]: \u001b[0mOverall training speed: 1998 iterations in 0:37:55 (1.1390 s / it)\n",
            "\u001b[32m[10/08 07:05:58 d2.engine.hooks]: \u001b[0mTotal training time: 0:41:06 (0:03:10 on hooks)\n",
            "\u001b[32m[10/08 07:05:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [Resize(shape=(400, 400))]\n",
            "\u001b[32m[10/08 07:05:58 d2.data.datasets.coco]: \u001b[0mLoaded 1435 images in COCO format from /tf/datasets/final-dataset/detectron2-dataset/val/_annotations.coco.json\n",
            "\u001b[32m[10/08 07:05:58 d2.data.common]: \u001b[0mSerializing 1435 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[10/08 07:05:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[10/08 07:05:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 1435 batches\n",
            "\u001b[32m[10/08 07:05:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/1435. Dataloading: 0.0004 s/iter. Inference: 0.0469 s/iter. Eval: 0.0002 s/iter. Total: 0.0475 s/iter. ETA=0:01:07\n",
            "\u001b[32m[10/08 07:06:03 d2.evaluation.evaluator]: \u001b[0mInference done 121/1435. Dataloading: 0.0028 s/iter. Inference: 0.0427 s/iter. Eval: 0.0002 s/iter. Total: 0.0457 s/iter. ETA=0:01:00\n",
            "\u001b[32m[10/08 07:06:09 d2.evaluation.evaluator]: \u001b[0mInference done 231/1435. Dataloading: 0.0032 s/iter. Inference: 0.0424 s/iter. Eval: 0.0002 s/iter. Total: 0.0458 s/iter. ETA=0:00:55\n",
            "\u001b[32m[10/08 07:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 345/1435. Dataloading: 0.0027 s/iter. Inference: 0.0424 s/iter. Eval: 0.0002 s/iter. Total: 0.0453 s/iter. ETA=0:00:49\n",
            "\u001b[32m[10/08 07:06:19 d2.evaluation.evaluator]: \u001b[0mInference done 464/1435. Dataloading: 0.0024 s/iter. Inference: 0.0419 s/iter. Eval: 0.0002 s/iter. Total: 0.0445 s/iter. ETA=0:00:43\n",
            "\u001b[32m[10/08 07:06:24 d2.evaluation.evaluator]: \u001b[0mInference done 575/1435. Dataloading: 0.0021 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0446 s/iter. ETA=0:00:38\n",
            "\u001b[32m[10/08 07:06:29 d2.evaluation.evaluator]: \u001b[0mInference done 704/1435. Dataloading: 0.0019 s/iter. Inference: 0.0415 s/iter. Eval: 0.0002 s/iter. Total: 0.0436 s/iter. ETA=0:00:31\n",
            "\u001b[32m[10/08 07:06:34 d2.evaluation.evaluator]: \u001b[0mInference done 833/1435. Dataloading: 0.0017 s/iter. Inference: 0.0410 s/iter. Eval: 0.0002 s/iter. Total: 0.0428 s/iter. ETA=0:00:25\n",
            "\u001b[32m[10/08 07:06:39 d2.evaluation.evaluator]: \u001b[0mInference done 963/1435. Dataloading: 0.0016 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:19\n",
            "\u001b[32m[10/08 07:06:44 d2.evaluation.evaluator]: \u001b[0mInference done 1094/1435. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:14\n",
            "\u001b[32m[10/08 07:06:49 d2.evaluation.evaluator]: \u001b[0mInference done 1224/1435. Dataloading: 0.0014 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:08\n",
            "\u001b[32m[10/08 07:06:54 d2.evaluation.evaluator]: \u001b[0mInference done 1353/1435. Dataloading: 0.0013 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:03\n",
            "\u001b[32m[10/08 07:06:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:58.719623 (0.041063 s / iter per device, on 1 devices)\n",
            "\u001b[32m[10/08 07:06:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:56 (0.039497 s / iter per device, on 1 devices)\n",
            "\u001b[32m[10/08 07:06:57 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[10/08 07:06:57 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
            "\u001b[32m[10/08 07:06:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[10/08 07:06:57 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[10/08 07:06:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.25 seconds.\n",
            "\u001b[32m[10/08 07:06:57 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[10/08 07:06:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.785\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.492\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.563\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571\n",
            "\u001b[32m[10/08 07:06:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 39.072 | 78.482 | 27.942 | 7.023 | 39.673 | 45.403 |\n",
            "\u001b[32m[10/08 07:06:57 d2.engine.defaults]: \u001b[0mEvaluation results for custom_dataset_val in csv format:\n",
            "\u001b[32m[10/08 07:06:57 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[10/08 07:06:57 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[10/08 07:06:57 d2.evaluation.testing]: \u001b[0mcopypaste: 39.0719,78.4825,27.9416,7.0232,39.6731,45.4035\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache() \n",
        "\n",
        "trainer = CocoTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run tensorboard\n",
        "# !tensorboard --logdir=/tf/notebooks/CEIA/computer-vision-2/tp-final/runs/train --host 0.0.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/08 11:14:05 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[10/08 11:14:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [Resize(shape=(400, 400))]\n",
            "\u001b[32m[10/08 11:14:05 d2.data.datasets.coco]: \u001b[0mLoaded 718 images in COCO format from /tf/datasets/final-dataset/detectron2-dataset/test/_annotations.coco.json\n",
            "\u001b[32m[10/08 11:14:05 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
            "\u001b[36m|   category    | #instances   |\n",
            "|:-------------:|:-------------|\n",
            "| license_plate | 718          |\n",
            "|               |              |\u001b[0m\n",
            "\u001b[32m[10/08 11:14:05 d2.data.common]: \u001b[0mSerializing 718 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[10/08 11:14:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.18 MiB\n",
            "\u001b[32m[10/08 11:14:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 718 batches\n",
            "\u001b[32m[10/08 11:14:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/718. Dataloading: 0.0008 s/iter. Inference: 0.0474 s/iter. Eval: 0.0002 s/iter. Total: 0.0483 s/iter. ETA=0:00:34\n",
            "\u001b[32m[10/08 11:14:11 d2.evaluation.evaluator]: \u001b[0mInference done 123/718. Dataloading: 0.0020 s/iter. Inference: 0.0426 s/iter. Eval: 0.0002 s/iter. Total: 0.0448 s/iter. ETA=0:00:26\n",
            "\u001b[32m[10/08 11:14:16 d2.evaluation.evaluator]: \u001b[0mInference done 231/718. Dataloading: 0.0029 s/iter. Inference: 0.0425 s/iter. Eval: 0.0002 s/iter. Total: 0.0456 s/iter. ETA=0:00:22\n",
            "\u001b[32m[10/08 11:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 349/718. Dataloading: 0.0021 s/iter. Inference: 0.0422 s/iter. Eval: 0.0002 s/iter. Total: 0.0445 s/iter. ETA=0:00:16\n",
            "\u001b[32m[10/08 11:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 477/718. Dataloading: 0.0018 s/iter. Inference: 0.0411 s/iter. Eval: 0.0002 s/iter. Total: 0.0431 s/iter. ETA=0:00:10\n",
            "\u001b[32m[10/08 11:14:31 d2.evaluation.evaluator]: \u001b[0mInference done 606/718. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:04\n",
            "\u001b[32m[10/08 11:14:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.819485 (0.041823 s / iter per device, on 1 devices)\n",
            "\u001b[32m[10/08 11:14:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:28 (0.040079 s / iter per device, on 1 devices)\n",
            "\u001b[32m[10/08 11:14:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[10/08 11:14:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
            "\u001b[32m[10/08 11:14:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[10/08 11:14:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[10/08 11:14:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
            "\u001b[32m[10/08 11:14:35 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[10/08 11:14:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.404\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.794\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.546\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.291\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.566\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568\n",
            "\u001b[32m[10/08 11:14:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 40.353 | 79.441 | 30.322 | 16.684 | 41.438 | 44.973 |\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 40.35250476360136,\n",
              "               'AP50': 79.44063866583815,\n",
              "               'AP75': 30.321568188808286,\n",
              "               'APs': 16.68424210689909,\n",
              "               'APm': 41.4377444524639,\n",
              "               'APl': 44.972794621546285})])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#test evaluation\n",
        "# from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "# from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"custom_dataset_test\", cfg, False, output_dir=\"./output/\")\n",
        "mapper = DatasetMapper(cfg, is_train=False, augmentations=[T.Resize((400, 400))])\n",
        "test_loader = build_detection_test_loader(cfg, \"custom_dataset_test\", mapper=mapper)\n",
        "# test_loader = build_detection_test_loader(cfg, \"custom_dataset_test\")\n",
        "inference_on_dataset(trainer.model, test_loader, evaluator) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.DATASETS.TEST = (\"my_dataset_test\", )\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
        "predictor = DefaultPredictor(cfg)\n",
        "test_metadata = MetadataCatalog.get(\"my_dataset_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "namespace(name='my_dataset_test')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_metadata"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
