{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_PATH = \"/tf/notebooks/CEIA/computer-vision-2/tp-final/models/yolov7\"\n",
        "\n",
        "import os\n",
        "\n",
        "# !pip install -r {os.path.join(BASE_PATH, \"yolov7/requirements.txt\")}\n",
        "# !apt-get update\n",
        "# !apt-get install ffmpeg libsm6 libxext6 -y\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bUbmy674bhpD"
      },
      "outputs": [],
      "source": [
        "PRETRAINED_PATH = os.path.join(BASE_PATH, \"yolov7-pretrained\")\n",
        "WEIGHTS_FILE = os.path.join(PRETRAINED_PATH, \"yolov7_training.pt\")\n",
        "\n",
        "if os.access(WEIGHTS_FILE, os.F_OK) is False:\n",
        "    try:\n",
        "        original_umask = os.umask(0)\n",
        "        os.mkdir(PRETRAINED_PATH, mode=0o775)\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "    finally:\n",
        "        os.umask(original_umask)\n",
        "\n",
        "    # download COCO starting checkpoint\n",
        "    !wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt -P {PRETRAINED_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUNS_PATH = \"/tf/notebooks/CEIA/computer-vision-2/tp-final/runs\"\n",
        "TRAIN_PROJECT_PATH = os.path.join(RUNS_PATH, \"train\")\n",
        "TRAIN_SCRIPT = os.path.join(BASE_PATH, \"yolov7/train.py\")\n",
        "DATASET_PATH = \"/tf/datasets/final-dataset/yolov7-dataset\"\n",
        "DATA_YAML = os.path.join(DATASET_PATH, \"data.yaml\")\n",
        "\n",
        "NUM_BATCHES = 4\n",
        "NUM_EPOCHS = 50\n",
        "FREEZE_LAYERS = 50 # backbone\n",
        "IMG_SIZE = 640\n",
        "experiment = \"yolov7-50-epochs-640-2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1iqOPKjr22mL"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache() \n",
        "\n",
        "!python {TRAIN_SCRIPT} \\\n",
        "--project {TRAIN_PROJECT_PATH} \\\n",
        "--name {experiment} \\\n",
        "--batch {NUM_BATCHES} \\\n",
        "--epochs {NUM_EPOCHS} \\\n",
        "--data {DATA_YAML} \\\n",
        "--img-size {IMG_SIZE} {IMG_SIZE} \\\n",
        "--weights {WEIGHTS_FILE} \\\n",
        "--device 0 \\\n",
        "--freeze {FREEZE_LAYERS}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run tensorboard\n",
        "# !tensorboard --logdir=/tf/notebooks/CEIA/computer-vision-2/tp-final/runs/train --host 0.0.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(augment=False, batch_size=4, conf_thres=0.7, data='/tf/datasets/final-dataset/yolov7-dataset/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='test', no_trace=False, project='/tf/notebooks/CEIA/computer-vision-2/tp-final/runs/train/yolov7-50-epochs-640', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='test', v5_metric=False, verbose=True, weights=['/tf/notebooks/CEIA/computer-vision-2/tp-final/runs/train/yolov7-50-epochs-640/weights/best.pt'])\n",
            "YOLOR ðŸš€ v0.1-112-g55b90e1 torch 1.12.1+cu102 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11177.25MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning '/tf/datasets/final-dataset/yolov7-dataset/test/labels.cache' ima\u001b[0m\n",
            "               Class      Images      Labels           P           R      mAP@.5\n",
            "                 all         718         718       0.938       0.922       0.912       0.821\n",
            "Speed: 14.1/0.9/15.0 ms inference/NMS/total per 640x640 image at batch-size 4\n",
            "Results saved to /tf/notebooks/CEIA/computer-vision-2/tp-final/runs/train/yolov7-50-epochs-640/test\n"
          ]
        }
      ],
      "source": [
        "TEST_PROJECT_PATH = os.path.join(TRAIN_PROJECT_PATH, f\"{experiment}\")\n",
        "TEST_SCRIPT = os.path.join(BASE_PATH, \"yolov7/test.py\")\n",
        "TEST_WEIGHTS = os.path.join(TRAIN_PROJECT_PATH, f\"{experiment}/weights/best.pt\")\n",
        "TEST_DATA_PATH = os.path.join(DATASET_PATH, \"test/images\")\n",
        "TEST_NAME = 'test'\n",
        "\n",
        "CONFIDENCE_THRESHOLD = 0.7\n",
        "\n",
        "!python {TEST_SCRIPT} \\\n",
        " --project {TEST_PROJECT_PATH} \\\n",
        " --name {TEST_NAME} \\\n",
        " --batch {NUM_BATCHES} \\\n",
        " --task test \\\n",
        " --data {DATA_YAML} \\\n",
        " --img-size {IMG_SIZE} \\\n",
        " --weights {TEST_WEIGHTS} \\\n",
        " --conf-thres {CONFIDENCE_THRESHOLD} \\\n",
        " --device 0 \\\n",
        " --verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DETECT_SCRIPT = os.path.join(BASE_PATH, \"yolov7/detect.py\")\n",
        "# DETECT_DATA_PATH = os.path.join(DATASET_PATH, \"test/images\")\n",
        "# DETECT_NAME = 'detect'\n",
        "\n",
        "# !python {DETECT_SCRIPT} \\\n",
        "#  --project {TEST_PROJECT_PATH} \\\n",
        "#  --name {DETECT_NAME} \\\n",
        "#  --weights {TEST_WEIGHTS} \\\n",
        "#  --conf-thres {CONFIDENCE_THRESHOLD} \\\n",
        "#  --source {DETECT_DATA_PATH}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
